# Spotify Data Engineering Pipeline

## Contexte et Objectif

Ce projet vise √† construire un pipeline de traitement complet pour l'historique d'√©coute Spotify, allant de l'ingestion des donn√©es brutes √† leur exposition via une API, en passant par le nettoyage, l'enrichissement et le stockage dans une base NoSQL.

### Technologies Utilis√©es

- **Python**: Pour l'extraction, la transformation et le nettoyage des donn√©es.
- **Pandas & Apache Spark**: Pour la manipulation et la transformation des donn√©es.
- **MongoDB**: Pour le stockage des donn√©es nettoy√©es.
- **FastAPI**: Pour l'exposition des donn√©es via une API REST.
- **Apache Airflow**: Pour l'automatisation et l'orchestration du pipeline.

## Description du Dataset

Le fichier `SpotifyHistory.csv` contient 149 860 enregistrements et 11 colonnes :

- `spotify_track_uri`: Identifiant unique du morceau sur Spotify.
- `ts`: Timestamp de lecture (YYYY-MM-DD HH:MM:SS).
- `platform`: Plateforme d‚Äô√©coute (web player, android, ios).
- `ms_played`: Dur√©e d‚Äô√©coute en millisecondes.
- `track_name`: Nom du morceau jou√©.
- `artist_name`: Nom de l‚Äôartiste.
- `album_name`: Nom de l‚Äôalbum associ√© au morceau.
- `reason_start`: Raison du d√©marrage de la lecture.
- `reason_end`: Raison de l‚Äôarr√™t du morceau.
- `shuffle`: Mode al√©atoire (True ou False).
- `skipped`: Morceau saut√© (True ou False).

## Pipeline de Traitement

### 1. Extraction des donn√©es

Lisez le fichier CSV et chargez les donn√©es dans un DataFrame.

### 2. Transformation et Nettoyage des Donn√©es

Appliquez les r√®gles suivantes :
- Remplacement des valeurs manquantes.
- Conversion des types.
- Cr√©ation de nouvelles colonnes (`minutes_played`, `day_of_week`, `hour_of_day`).
- Nettoyage des cha√Ænes de caract√®res.
- Suppression des doublons.
- Filtrage des √©coutes de moins de 5 secondes.

### 3. Chargement dans MongoDB

Ins√©rez les donn√©es transform√©es dans une base MongoDB (base de donn√©es : `spotify_history`, collection : `history`).

### 4. Exposition via une API FastAPI

Cr√©ez une API REST permettant :
- CRUD : Ajout, mise √† jour, suppression, consultation des √©coutes.
- Statistiques : Top artistes, titres, albums, taux de morceaux saut√©s, r√©partition par jour/heure.

### 5. Automatisation avec Apache Airflow

D√©finissez un DAG Airflow pour orchestrer le pipeline et ex√©cuter automatiquement les √©tapes.

## Structure du Projet

```markdown
üìÅ data/
  - spotify_history.csv: Fichier contenant les donn√©es sources.

üìÅ scripts/
  - extract.py: Extraction des donn√©es depuis le CSV.
  - transform.py: Nettoyage et enrichissement des donn√©es.
  - load.py: Insertion des donn√©es dans MongoDB.

üìÅ fastapi_app/
  - main.py: Code de l‚ÄôAPI FastAPI avec les endpoints CRUD et statistiques.

üìÅ dags/
  - spotify_pipeline_dag.py: D√©finition du DAG Airflow pour orchestrer le pipeline.

üìÑ requirements.txt: Liste des d√©pendances Python n√©cessaires au projet.

### 6. Installation et Ex√©cution (Github codespaces (Recommended))

Create Github codespaces :

![image](image.png)

python -m venv venv
source venv/bin/activate

pip install -r requirements.txt

Installing MongoDB :
Import the public key used by the package management system:
wget -qO - https://www.mongodb.org/static/pgp/server-4.4.asc | sudo apt-key add -
Create a list file for MongoDB:
echo "deb [ arch=amd64,arm64 ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/4.4 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-4.4.list
Reload local package database:
sudo apt-get update
Install the MongoDB packages:
sudo apt-get install -y mongodb-org
Create the Data Directory:
sudo mkdir -p /data/db
sudo chown -R `id -u` /data/db
Start MongoDB:
mongod --dbpath /data/db
Verify MongoDB is Running:
mongo

uvicorn fastapi_app.main:app --reload

[core]
# The folder where your airflow pipelines live, most likely a
# subfolder in a code repository. This path must be absolute.
#
# Variable: AIRFLOW__CORE__DAGS_FOLDER
#
#dags_folder = /home/codespace/airflow/dags
dags_folder = /workspaces/tp_data_python_mongo_api_2/dags/

[webserver]
enable_proxy_fix = True

airflow standalone
